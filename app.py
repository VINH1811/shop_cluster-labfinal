import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.cluster import AgglomerativeClustering, DBSCAN, KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(
    page_title="B√°o c√°o ƒê·ªì √°n Data Mining",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS T√ôY CH·ªàNH ---
st.markdown("""
    <style>
    .main { background-color: #f5f5f5; }
    h1 { color: #2c3e50; }
    h2 { color: #34495e; }
    .stMetric { background-color: #ffffff; padding: 15px; border-radius: 5px; box-shadow: 1px 1px 3px #ccc; }
    </style>
    """, unsafe_allow_html=True)

# --- 1. H√ÄM T·∫¢I D·ªÆ LI·ªÜU ---
@st.cache_data
def load_data():
    try:
        # ƒê·ªçc d·ªØ li·ªáu
        df_final = pd.read_csv('data/processed/customer_clusters_final.csv', dtype={'CustomerID': str})
        df_rules = pd.read_csv('data/processed/rules_apriori_filtered.csv')
        return df_final, df_rules
    except FileNotFoundError:
        st.error("‚ùå L·ªói: Thi·∫øu file d·ªØ li·ªáu. Vui l√≤ng upload 'customer_clusters_final.csv' v√† 'rules_apriori_filtered.csv'.")
        return None, None

df_final, df_rules = load_data()

# --- 2. H√ÄM T√çNH TO√ÅN N√ÇNG CAO (CACHED) ---
@st.cache_resource
def run_model_comparison(data):
    # L·∫•y m·∫´u ng·∫´u nhi√™n n·∫øu d·ªØ li·ªáu > 5000 d√≤ng ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô demo
    if len(data) > 5000:
        X = data[['Recency', 'Frequency', 'Monetary']].sample(5000, random_state=42).values
    else:
        X = data[['Recency', 'Frequency', 'Monetary']].values
        
    results = []
    
    # 1. K-Means (Baseline - K=5)
    kmeans = KMeans(n_clusters=5, random_state=42)
    labels_km = kmeans.fit_predict(X)
    results.append(calculate_metrics(X, labels_km, "K-Means (K=5)"))
    
    # 2. Agglomerative (K=5)
    agg = AgglomerativeClustering(n_clusters=5)
    labels_agg = agg.fit_predict(X)
    results.append(calculate_metrics(X, labels_agg, "Agglomerative (K=5)"))
    
    # 3. DBSCAN
    dbscan = DBSCAN(eps=0.5, min_samples=20)
    labels_db = dbscan.fit_predict(X)
    results.append(calculate_metrics(X, labels_db, "DBSCAN"))
    
    return pd.DataFrame(results)

def calculate_metrics(X, labels, name):
    unique_labels = set(labels)
    # Lo·∫°i b·ªè nhi·ªÖu (-1) khi ƒë·∫øm s·ªë c·ª•m cho DBSCAN
    n_clusters = len(unique_labels) - (1 if -1 in labels else 0)
    
    if n_clusters < 2:
        return {"M√¥ h√¨nh": name, "Silhouette": -1, "DBI": -1, "S·ªë c·ª•m": n_clusters, "ƒê√°nh gi√°": "K√©m"}
        
    sil = silhouette_score(X, labels)
    dbi = davies_bouldin_score(X, labels)
    
    return {
        "M√¥ h√¨nh": name, 
        "Silhouette (C√†ng cao c√†ng t·ªët)": round(sil, 3), 
        "DBI (C√†ng th·∫•p c√†ng t·ªët)": round(dbi, 3), 
        "S·ªë c·ª•m": n_clusters,
        "ƒê√°nh gi√°": "T·ªët" if sil > 0.5 else "Trung b√¨nh"
    }

# --- 3. SIDEBAR ---
st.sidebar.title("üóÇÔ∏è M·ª•c l·ª•c B√°o c√°o")
page = st.sidebar.radio("Ch·ªçn ph·∫ßn b√°o c√°o:", [
    "1. T·ªïng quan D·ª± √°n",
    "2. Ph√¢n kh√∫c Kh√°ch h√†ng (RFM)",
    "3. Lu·∫≠t k·∫øt h·ª£p (Apriori)",
    "4. [N√¢ng cao] So s√°nh M√¥ h√¨nh",
    "5. [N√¢ng cao] Ph√¢n c·ª•m Lu·∫≠t V√†ng",
    "6. Tra c·ª©u & ·ª®ng d·ª•ng"
])

st.sidebar.markdown("---")
st.sidebar.info("ƒê·ªì √°n Data Mining\n\nGVHD: ThS.L√™ Th·ªã Th√πy Trang\n\nNh√≥m th·ª±c hi·ªán: Nh√≥m WL")

# --- 4. N·ªòI DUNG CH√çNH ---

if df_final is not None:
    
    # === TRANG 1: T·ªîNG QUAN ===
    if page == "1. T·ªïng quan D·ª± √°n":
        st.title("üìë T·ªïng quan D·ª± √°n Ph√¢n t√≠ch Kh√°ch h√†ng")
        st.markdown("""
        ### M·ª•c ti√™u:
        X√¢y d·ª±ng h·ªá th·ªëng ph√¢n kh√∫c kh√°ch h√†ng v√† g·ª£i √Ω s·∫£n ph·∫©m d·ª±a tr√™n d·ªØ li·ªáu giao d·ªãch b√°n l·∫ª.
        
        ### C√°c n·ªôi dung ƒë√£ th·ª±c hi·ªán:
        1.  **Ti·ªÅn x·ª≠ l√Ω:** L√†m s·∫°ch d·ªØ li·ªáu, x·ª≠ l√Ω Null, Duplicate.
        2.  **RFM Analysis:** T√≠nh to√°n ch·ªâ s·ªë Recency, Frequency, Monetary.
        3.  **Clustering:** Ph√¢n c·ª•m kh√°ch h√†ng b·∫±ng K-Means (K=5).
        4.  **Association Rules:** T√¨m lu·∫≠t k·∫øt h·ª£p b·∫±ng thu·∫≠t to√°n Apriori.
        5.  **N√¢ng cao:** So s√°nh c√°c thu·∫≠t to√°n ph√¢n c·ª•m & Ph√¢n nh√≥m lu·∫≠t b√°n h√†ng.
        """)
        
        st.markdown("---")
        c1, c2, c3 = st.columns(3)
        c1.metric("T·ªïng s·ªë Kh√°ch h√†ng", f"{len(df_final):,}")
        c2.metric("S·ªë l∆∞·ª£ng C·ª•m KH", df_final['cluster'].nunique())
        c3.metric("T·ªïng s·ªë Lu·∫≠t t√¨m ƒë∆∞·ª£c", f"{len(df_rules):,}")

    # === TRANG 2: PH√ÇN KH√öC KH√ÅCH H√ÄNG (RFM) ===
    elif page == "2. Ph√¢n kh√∫c Kh√°ch h√†ng (RFM)":
        st.title("üë• K·∫øt qu·∫£ Ph√¢n kh√∫c Kh√°ch h√†ng (K-Means)")
        
        col1, col2 = st.columns([3, 1])
        with col1:
            st.subheader("Bi·ªÉu ƒë·ªì 3D Kh√¥ng gian RFM")
            fig_3d = px.scatter_3d(df_final, x='Recency', y='Frequency', z='Monetary',
                                   color='cluster', title='Ph√¢n b·ªë 5 c·ª•m kh√°ch h√†ng',
                                   color_continuous_scale='Viridis', opacity=0.8)
            st.plotly_chart(fig_3d, use_container_width=True)
        
        with col2:
            st.subheader("Ph√¢n b·ªë S·ªë l∆∞·ª£ng")
            cluster_counts = df_final['cluster'].value_counts().reset_index()
            cluster_counts.columns = ['Cluster', 'Count']
            st.dataframe(cluster_counts, hide_index=True)
            st.markdown("**Nh·∫≠n x√©t:** C·ª•m 0 chi·∫øm ƒëa s·ªë (Long Tail), c√°c c·ª•m c√≤n l·∫°i l√† nh√≥m ƒë·∫∑c bi·ªát.")

        st.markdown("---")
        st.subheader("ƒê·∫∑c ƒëi·ªÉm h√†nh vi t·ª´ng c·ª•m (Boxplot)")
        tab_r, tab_f, tab_m = st.tabs(["Recency (G·∫ßn ƒë√¢y)", "Frequency (T·∫ßn su·∫•t)", "Monetary (Ti·ªÅn)"])
        
        with tab_r:
            st.plotly_chart(px.box(df_final, x='cluster', y='Recency', color='cluster'), use_container_width=True)
        with tab_f:
            st.plotly_chart(px.box(df_final, x='cluster', y='Frequency', color='cluster'), use_container_width=True)
        with tab_m:
            st.plotly_chart(px.box(df_final, x='cluster', y='Monetary', color='cluster'), use_container_width=True)

    # === TRANG 3: LU·∫¨T K·∫æT H·ª¢P ===
    elif page == "3. Lu·∫≠t k·∫øt h·ª£p (Apriori)":
        st.title("üîó Ph√¢n t√≠ch Gi·ªè h√†ng (Market Basket Analysis)")
        
        st.subheader("M·ªëi quan h·ªá Support - Confidence - Lift")
        fig_rules = px.scatter(df_rules, x="support", y="confidence", size="lift", color="lift",
                               hover_data=['antecedents_str', 'consequents_str'],
                               title="Tr·ª±c quan h√≥a c√°c lu·∫≠t k·∫øt h·ª£p",
                               labels={'lift': 'Lift (S·ª©c m·∫°nh)'})
        st.plotly_chart(fig_rules, use_container_width=True)
        
        st.subheader("Top c√°c lu·∫≠t m·∫°nh nh·∫•t")
        st.dataframe(df_rules[['antecedents_str', 'consequents_str', 'support', 'confidence', 'lift']].sort_values('lift', ascending=False).head(20))

    # === TRANG 4: SO S√ÅNH M√î H√åNH (N√ÇNG CAO 1) ===
    elif page == "4. [N√¢ng cao] So s√°nh M√¥ h√¨nh":
        st.title("üî¨ Y√™u c·∫ßu N√¢ng cao 1: So s√°nh thu·∫≠t to√°n Ph√¢n c·ª•m")
        st.markdown("""
        Ch√∫ng t√¥i ƒë√£ th·ª≠ nghi·ªám th√™m **Agglomerative Clustering** v√† **DBSCAN** ƒë·ªÉ so s√°nh v·ªõi **K-Means**.
        K·∫øt qu·∫£ ƒë√°nh gi√° d·ª±a tr√™n Silhouette Score v√† Davies-Bouldin Index.
        """)
        
        if st.button("üöÄ Ch·∫°y so s√°nh (M·∫•t kho·∫£ng 5-10s)"):
            with st.spinner("ƒêang hu·∫•n luy·ªán c√°c m√¥ h√¨nh..."):
                comparison_df = run_model_comparison(df_final)
            
            st.success("Ho√†n t·∫•t!")
            st.table(comparison_df)
            
            st.markdown("""
            ### üìù K·∫øt lu·∫≠n r√∫t ra:
            * **K-Means (Hi·ªán t·∫°i):** Ph√¢n chia kh√° t·ªët v·ªÅ m·∫∑t nghi·ªáp v·ª• (5 nh√≥m r√µ r√†ng), nh∆∞ng ch·ªâ s·ªë Silhouette th·∫•p do d·ªØ li·ªáu nhi·ªÖu.
            * **Agglomerative Clustering:** Cho ch·ªâ s·ªë **Silhouette cao h∆°n**, c√°c c·ª•m t√°ch bi·ªát r√µ h∆°n. ƒê√¢y l√† h∆∞·ªõng c·∫£i thi·ªán ti·ªÅm nƒÉng.
            * **DBSCAN:** Ch·ªâ t√¨m th·∫•y 2 c·ª•m (1 c·ª•m ch√≠nh v√† nhi·ªÖu), **kh√¥ng c√≥ t√≠nh ·ª©ng d·ª•ng (Actionable)** trong marketing v√¨ gom h·∫øt kh√°ch h√†ng v√†o 1 nh√≥m.
            """)

    # === TRANG 5: PH√ÇN C·ª§M LU·∫¨T (N√ÇNG CAO 2) ===
    elif page == "5. [N√¢ng cao] Ph√¢n c·ª•m Lu·∫≠t V√†ng":
        st.title("üíé Y√™u c·∫ßu N√¢ng cao 2: Ph√¢n c·ª•m Lu·∫≠t & T√¨m 'Lu·∫≠t V√†ng'")
        st.markdown("Thay v√¨ nh√¨n danh s√°ch lu·∫≠t h·ªón ƒë·ªôn, ch√∫ng t√¥i √°p d·ª•ng K-Means ƒë·ªÉ gom nh√≥m c√°c lu·∫≠t b√°n h√†ng.")

        # X·ª≠ l√Ω ph√¢n c·ª•m lu·∫≠t
        rule_features = df_rules[['support', 'confidence', 'lift']]
        scaler = StandardScaler()
        X_rules = scaler.fit_transform(rule_features)
        
        kmeans_rules = KMeans(n_clusters=3, random_state=42)
        df_rules['rule_cluster'] = kmeans_rules.fit_predict(X_rules)
        
        # T√¨m c·ª•m v√†ng
        summary = df_rules.groupby('rule_cluster')['lift'].mean()
        gold_id = summary.idxmax()
        gold_rules = df_rules[df_rules['rule_cluster'] == gold_id].sort_values('lift', ascending=False)
        
        c1, c2 = st.columns([1, 1])
        with c1:
            st.write("### Th·ªëng k√™ 3 nh√≥m lu·∫≠t:")
            st.dataframe(df_rules.groupby('rule_cluster')[['support', 'confidence', 'lift', 'rule_str']].agg({'lift': 'mean', 'confidence': 'mean', 'rule_str': 'count'}).rename(columns={'rule_str': 'S·ªë l∆∞·ª£ng Lu·∫≠t'}))
        
        with c2:
            st.write("### Nh·∫≠n di·ªán nh√≥m:")
            st.info(f"üèÜ **Cluster {gold_id} l√† NH√ìM V√ÄNG (Gold Rules)**")
            st.write(f"- Lift trung b√¨nh c·ª±c cao: **{summary.max():.2f}**")
            st.write(f"- S·ªë l∆∞·ª£ng lu·∫≠t: **{len(gold_rules)}**")
            
        st.markdown("---")
        st.subheader(f"Danh s√°ch {len(gold_rules)} Lu·∫≠t V√†ng (D√πng ƒë·ªÉ t·∫°o Combo ngay)")
        st.dataframe(gold_rules[['antecedents_str', 'consequents_str', 'lift', 'confidence']])
        
        # N√∫t t·∫£i v·ªÅ
        csv = gold_rules.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üì• T·∫£i danh s√°ch Lu·∫≠t V√†ng (.csv)",
            data=csv,
            file_name='gold_rules_82.csv',
            mime='text/csv',
        )

    # === TRANG 6: TRA C·ª®U ===
    elif page == "6. Tra c·ª©u & ·ª®ng d·ª•ng":
        st.title("üîç Tra c·ª©u th√¥ng tin Kh√°ch h√†ng")
        cust_id = st.text_input("Nh·∫≠p Customer ID (VD: 012346):")
        
        if cust_id:
            cust = df_final[df_final['CustomerID'] == cust_id]
            if not cust.empty:
                info = cust.iloc[0]
                st.success(f"Kh√°ch h√†ng: **{cust_id}**")
                c1, c2, c3, c4 = st.columns(4)
                c1.metric("Thu·ªôc C·ª•m", int(info['cluster']))
                c2.metric("Recency", f"{info['Recency']:.2f}")
                c3.metric("Frequency", f"{info['Frequency']:.2f}")
                c4.metric("Monetary", f"{info['Monetary']:.2f}")
                
                # G·ª£i √Ω chi·∫øn l∆∞·ª£c
                st.subheader("üí° G·ª£i √Ω chi·∫øn l∆∞·ª£c:")
                if info['cluster'] == 0:
                    st.write("- ƒê√¢y l√† kh√°ch h√†ng ph·ªï th√¥ng. N√™n g·ª≠i email t·ª± ƒë·ªông c√°c s·∫£n ph·∫©m m·ªõi.")
                elif info['cluster'] in [1, 2, 3, 4]:
                    st.write("- ƒê√¢y l√† kh√°ch h√†ng VIP/ƒê·∫∑c bi·ªát. C·∫ßn telesale chƒÉm s√≥c ri√™ng ho·∫∑c t·∫∑ng m√£ gi·∫£m gi√° cao.")
            else:
                st.error("Kh√¥ng t√¨m th·∫•y ID n√†y.")

else:
    st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu.")